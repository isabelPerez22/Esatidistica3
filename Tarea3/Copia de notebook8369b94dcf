{"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false},"colab":{"name":"notebook8369b94dcf","provenance":[{"file_id":"https://storage.googleapis.com/kaggle-colab-exported-notebooks/notebook8369b94dcf-2655104e-4055-489e-b0b9-93170bfa1847.ipynb?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com/20240513/auto/storage/goog4_request&X-Goog-Date=20240513T021300Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=9572b6c3579eb9428fb76967b754853323b0a1e30ae256bc235e2ee21587552122084dbe7691ef32c1e218e4801c3120829fa6e6979f55765d20f012e0e55e54eea443e9d5610a0559c3ed7c86d0a31d07913e414eea6ad4c133064f99e95e77f565d2b6de263ee2f96b6c101d9c849a1ebc27157d450ecdd676b2b61ae5df6dd89fb5d098ac12b29393a417e44cc73a497230a38fe86d006c483f53ca2693b786c2499cb51803bf4b260cb4395197b0e3a63c5d891767ca9f0059840e8a609be88eea4d6fd26ddd52e664a92d56075908e8be3ade4d9359cad7820be9aac33d379e99800661245cc13b20540b1db7c80c595bd2abfb0993e4d52f8f21bfca4b","timestamp":1715915523297}],"toc_visible":true,"machine_shape":"hm","gpuType":"T4"},"accelerator":"GPU"},"nbformat_minor":0,"nbformat":4,"cells":[{"cell_type":"code","source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"],"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"id":"5HqAW6oXuYzr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from numpy.random import seed\n","seed(101)\n","\n","import pandas as pd\n","import numpy as np\n","\n","import tensorflow\n","\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.metrics import categorical_crossentropy\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n","\n","import os\n","import cv2\n","\n","import imageio\n","import skimage\n","import skimage.io\n","import skimage.transform\n","\n","from sklearn.utils import shuffle\n","from sklearn.metrics import confusion_matrix\n","from sklearn.model_selection import train_test_split\n","import itertools\n","import shutil\n","import matplotlib.pyplot as plt\n","%matplotlib inline"],"metadata":{"id":"8phgn114iv2J","executionInfo":{"status":"ok","timestamp":1715723535552,"user_tz":300,"elapsed":8382,"user":{"displayName":"","userId":""}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Number of samples we will have in each class.\n","SAMPLE_SIZE = 224\n","\n","# The images will all be resized to this size.\n","IMAGE_SIZE = 224"],"metadata":{"id":"Cwetl5Sa37Fm","executionInfo":{"status":"ok","timestamp":1715723538698,"user_tz":300,"elapsed":305,"user":{"displayName":"","userId":""}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["## se creo el modelo"],"metadata":{"id":"T0bdna6Y5F26","executionInfo":{"status":"ok","timestamp":1715723540859,"user_tz":300,"elapsed":272,"user":{"displayName":"","userId":""}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# Source: https://www.kaggle.com/fmarazzi/baseline-keras-cnn-roc-fast-5min-0-8253-lb\n","\n","kernel_size = (3,3)\n","pool_size= (2,2)\n","first_filters = 32\n","second_filters = 64\n","third_filters = 128\n","\n","dropout_conv = 0.3\n","dropout_dense = 0.3\n","\n","\n","model = Sequential()\n","model.add(Conv2D(first_filters, kernel_size, activation = 'relu',\n","                 input_shape = (IMAGE_SIZE, IMAGE_SIZE, 3)))\n","model.add(Conv2D(first_filters, kernel_size, activation = 'relu'))\n","model.add(Conv2D(first_filters, kernel_size, activation = 'relu'))\n","model.add(MaxPooling2D(pool_size = pool_size))\n","model.add(Dropout(dropout_conv))\n","\n","model.add(Conv2D(second_filters, kernel_size, activation ='relu'))\n","model.add(Conv2D(second_filters, kernel_size, activation ='relu'))\n","model.add(Conv2D(second_filters, kernel_size, activation ='relu'))\n","model.add(MaxPooling2D(pool_size = pool_size))\n","model.add(Dropout(dropout_conv))\n","\n","model.add(Conv2D(third_filters, kernel_size, activation ='relu'))\n","model.add(Conv2D(third_filters, kernel_size, activation ='relu'))\n","model.add(Conv2D(third_filters, kernel_size, activation ='relu'))\n","model.add(MaxPooling2D(pool_size = pool_size))\n","model.add(Dropout(dropout_conv))\n","\n","model.add(Flatten())\n","model.add(Dense(1024, activation = \"relu\")(x))\n","model.add(Dense(1024, activation = \"relu\")(x))\n","model.add(Dense(512, activation = \"relu\")(x))\n","model.add(Dropout(dropout_dense))\n","model.add(Dense(11, activation = \"softmax\")(x))\n","\n","model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MHtdDy51kIXc","executionInfo":{"status":"ok","timestamp":1715723542738,"user_tz":300,"elapsed":931,"user":{"displayName":"","userId":""}},"outputId":"e58c038e-e80d-4b8a-a568-2f5bfd548b01"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," conv2d (Conv2D)             (None, 222, 222, 32)      896       \n","                                                                 \n"," conv2d_1 (Conv2D)           (None, 220, 220, 32)      9248      \n","                                                                 \n"," conv2d_2 (Conv2D)           (None, 218, 218, 32)      9248      \n","                                                                 \n"," max_pooling2d (MaxPooling2  (None, 109, 109, 32)      0         \n"," D)                                                              \n","                                                                 \n"," dropout (Dropout)           (None, 109, 109, 32)      0         \n","                                                                 \n"," conv2d_3 (Conv2D)           (None, 107, 107, 64)      18496     \n","                                                                 \n"," conv2d_4 (Conv2D)           (None, 105, 105, 64)      36928     \n","                                                                 \n"," conv2d_5 (Conv2D)           (None, 103, 103, 64)      36928     \n","                                                                 \n"," max_pooling2d_1 (MaxPoolin  (None, 51, 51, 64)        0         \n"," g2D)                                                            \n","                                                                 \n"," dropout_1 (Dropout)         (None, 51, 51, 64)        0         \n","                                                                 \n"," conv2d_6 (Conv2D)           (None, 49, 49, 128)       73856     \n","                                                                 \n"," conv2d_7 (Conv2D)           (None, 47, 47, 128)       147584    \n","                                                                 \n"," conv2d_8 (Conv2D)           (None, 45, 45, 128)       147584    \n","                                                                 \n"," max_pooling2d_2 (MaxPoolin  (None, 22, 22, 128)       0         \n"," g2D)                                                            \n","                                                                 \n"," dropout_2 (Dropout)         (None, 22, 22, 128)       0         \n","                                                                 \n"," flatten (Flatten)           (None, 61952)             0         \n","                                                                 \n"," dense (Dense)               (None, 256)               15859968  \n","                                                                 \n"," dropout_3 (Dropout)         (None, 256)               0         \n","                                                                 \n"," dense_1 (Dense)             (None, 11)                2827      \n","                                                                 \n","=================================================================\n","Total params: 16343563 (62.35 MB)\n","Trainable params: 16343563 (62.35 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","import os\n","\n","# Directorio que contiene todas las imágenes\n","data_dir = '/content/drive/MyDrive/estadistica/uco-plant-seedlings-classification-01-2024/train'\n","\n","# Proporciones para la división de los datos\n","train_ratio = 0.7\n","val_ratio = 0.15\n","test_ratio = 0.15\n","\n","# Crear generadores de datos de imagen para cargar imágenes del directorio\n","datagen = ImageDataGenerator(rescale=1./255, validation_split=val_ratio)\n","\n","# Tamaño del lote (batch size) de imágenes a cargar en cada iteración\n","batch_size = 32\n","color_mode = 'rgb'\n","\n","# Cargar imágenes del directorio de entrenamiento y validación usando el generador de datos\n","train_generator = datagen.flow_from_directory(\n","    data_dir,\n","    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n","    color_mode=color_mode,\n","    batch_size=batch_size,\n","    class_mode='categorical',\n","    subset='training',\n","    shuffle=True)\n","\n","val_generator = datagen.flow_from_directory(\n","    data_dir,\n","    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n","    batch_size=batch_size,\n","    class_mode='categorical',\n","    subset='validation')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QSrvr97W4rfj","executionInfo":{"status":"ok","timestamp":1715723558490,"user_tz":300,"elapsed":7241,"user":{"displayName":"","userId":""}},"outputId":"c9fc0c41-8474-4777-d1dc-8f557cbd28cf"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 3619 images belonging to 11 classes.\n","Found 633 images belonging to 11 classes.\n"]}]},{"cell_type":"markdown","source":[],"metadata":{"id":"1WBxQ7x1KKix"}},{"cell_type":"code","source":["model.compile(Adam(lr=0.0001), loss='categorical_crossentropy',\n","              metrics=['accuracy'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TL-cMF_n57xp","executionInfo":{"status":"ok","timestamp":1715723563090,"user_tz":300,"elapsed":301,"user":{"displayName":"","userId":""}},"outputId":"80546563-e666-447e-a16e-708c2479bab1"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"]}]},{"cell_type":"code","source":["filepath = \"model.h5\"\n","checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1,\n","                             save_best_only=True, mode='max')\n","\n","reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=3,\n","                                   verbose=1, mode='max', min_lr=0.00001)\n","\n","\n","callbacks_list = [checkpoint, reduce_lr]\n","\n","# Calcular los pasos por época\n","train_steps = len(train_generator)// 15\n","val_steps = len(val_generator)// 15\n","\n","# Establecer estos valores en fit_generator\n","history = model.fit_generator(train_generator, steps_per_epoch=train_steps,\n","                    validation_data=val_generator,\n","                    validation_steps=val_steps,\n","                    epochs=40, verbose=1,\n","                   callbacks=callbacks_list)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y4GMuT186Oy2","outputId":"0438d0e7-2fb8-47c0-ec3b-093468117b34"},"execution_count":null,"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["<ipython-input-10-e9bb40aa18c1>:16: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  history = model.fit_generator(train_generator, steps_per_epoch=train_steps,\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch 1/40\n","7/7 [==============================] - ETA: 0s - loss: 2.5198 - accuracy: 0.1384 "]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["7/7 [==============================] - 138s 18s/step - loss: 2.5198 - accuracy: 0.1384 - val_loss: 2.3671 - val_accuracy: 0.0938 - lr: 0.0010\n","Epoch 2/40\n","7/7 [==============================] - ETA: 0s - loss: 2.3546 - accuracy: 0.1741 "]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["7/7 [==============================] - 139s 19s/step - loss: 2.3546 - accuracy: 0.1741 - val_loss: 2.3709 - val_accuracy: 0.1250 - lr: 0.0010\n","Epoch 3/40\n","7/7 [==============================] - ETA: 0s - loss: 2.3468 - accuracy: 0.1339 "]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["7/7 [==============================] - 131s 18s/step - loss: 2.3468 - accuracy: 0.1339 - val_loss: 2.3279 - val_accuracy: 0.2500 - lr: 0.0010\n","Epoch 4/40\n","7/7 [==============================] - ETA: 0s - loss: 2.3619 - accuracy: 0.1429 "]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["7/7 [==============================] - 135s 18s/step - loss: 2.3619 - accuracy: 0.1429 - val_loss: 2.2370 - val_accuracy: 0.2812 - lr: 0.0010\n","Epoch 5/40\n","7/7 [==============================] - ETA: 0s - loss: 2.3244 - accuracy: 0.1339 "]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["7/7 [==============================] - 136s 19s/step - loss: 2.3244 - accuracy: 0.1339 - val_loss: 2.2765 - val_accuracy: 0.1562 - lr: 0.0010\n","Epoch 6/40\n","7/7 [==============================] - ETA: 0s - loss: 2.3252 - accuracy: 0.1607 "]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["7/7 [==============================] - 125s 17s/step - loss: 2.3252 - accuracy: 0.1607 - val_loss: 2.2048 - val_accuracy: 0.1562 - lr: 0.0010\n","Epoch 7/40\n","7/7 [==============================] - ETA: 0s - loss: 2.3750 - accuracy: 0.1161 "]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["7/7 [==============================] - 132s 18s/step - loss: 2.3750 - accuracy: 0.1161 - val_loss: 2.3038 - val_accuracy: 0.2188 - lr: 0.0010\n","Epoch 8/40\n","7/7 [==============================] - ETA: 0s - loss: 2.3567 - accuracy: 0.1250 "]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["7/7 [==============================] - 124s 17s/step - loss: 2.3567 - accuracy: 0.1250 - val_loss: 2.3571 - val_accuracy: 0.0938 - lr: 0.0010\n","Epoch 9/40\n","7/7 [==============================] - ETA: 0s - loss: 2.3299 - accuracy: 0.1652 "]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["7/7 [==============================] - 119s 16s/step - loss: 2.3299 - accuracy: 0.1652 - val_loss: 2.3424 - val_accuracy: 0.2188 - lr: 0.0010\n","Epoch 10/40\n","7/7 [==============================] - ETA: 0s - loss: 2.3263 - accuracy: 0.1696 "]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["7/7 [==============================] - 126s 17s/step - loss: 2.3263 - accuracy: 0.1696 - val_loss: 2.2832 - val_accuracy: 0.0938 - lr: 0.0010\n","Epoch 11/40\n","7/7 [==============================] - ETA: 0s - loss: 2.3887 - accuracy: 0.0938 "]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n","WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"]},{"output_type":"stream","name":"stdout","text":["7/7 [==============================] - 122s 17s/step - loss: 2.3887 - accuracy: 0.0938 - val_loss: 2.3525 - val_accuracy: 0.1562 - lr: 0.0010\n","Epoch 12/40\n","3/7 [===========>..................] - ETA: 59s - loss: 2.3766 - accuracy: 0.1146 "]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount(\"/content/drive\", force_remount=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XKzSOSEZr-DS","executionInfo":{"status":"ok","timestamp":1715723460484,"user_tz":300,"elapsed":22510,"user":{"displayName":"","userId":""}},"outputId":"4d2a2d27-e600-4884-91de-e903c3894734"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["# Nueva sección"],"metadata":{"id":"TfVm1h_AgkG8"}}]}